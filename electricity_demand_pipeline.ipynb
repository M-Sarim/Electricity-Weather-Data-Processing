{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_electricity_data(electricity_folder: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and merge electricity data from JSON files.\n",
    "    \"\"\"\n",
    "    console.print(\"[yellow]Loading Electricity Data...[/yellow]\")\n",
    "    files = glob.glob(os.path.join(electricity_folder, \"*.json\"))\n",
    "    df_list = []\n",
    "    for file in track(files, description=\"Processing electricity JSON files...\"):\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            if \"response\" in data and \"data\" in data[\"response\"]:\n",
    "                df = pd.DataFrame(data[\"response\"][\"data\"])\n",
    "                if 'period' in df.columns and 'value' in df.columns:\n",
    "                    df.rename(columns={'period': 'timestamp', 'value': 'electricity_demand'}, inplace=True)\n",
    "                    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "                    df['electricity_demand'] = pd.to_numeric(df['electricity_demand'], errors='coerce')\n",
    "                    df.dropna(subset=['timestamp'], inplace=True)\n",
    "                    df_list.append(df)\n",
    "                else:\n",
    "                    console.print(f\"[red]⚠ Skipping {file}: Missing required columns.[/red]\")\n",
    "            else:\n",
    "                console.print(f\"[red]⚠ Skipping {file}: Incorrect JSON structure.[/red]\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]❌ Error processing {file}: {e}[/red]\")\n",
    "    merged_electricity = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n",
    "    console.print(f\"[green]✅ Loaded {len(merged_electricity)} electricity records.[/green]\")\n",
    "    return merged_electricity\n",
    "\n",
    "def load_weather_data(weather_folder: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and merge weather data from CSV files.\n",
    "    \"\"\"\n",
    "    console.print(\"[yellow]Loading Weather Data...[/yellow]\")\n",
    "    files = glob.glob(os.path.join(weather_folder, \"*.csv\"))\n",
    "    df_list = []\n",
    "    for file in track(files, description=\"Processing weather CSV files...\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]❌ Error processing {file}: {e}[/red]\")\n",
    "    merged_weather = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n",
    "    if not merged_weather.empty:\n",
    "        merged_weather.rename(columns={'date': 'timestamp'}, inplace=True)\n",
    "        merged_weather['timestamp'] = pd.to_datetime(merged_weather['timestamp'], errors='coerce')\n",
    "        merged_weather.dropna(subset=['timestamp'], inplace=True)\n",
    "    console.print(\"[green]✅ Weather Data Processed Successfully![/green]\")\n",
    "    return merged_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca367eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(electricity_df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure consistent timestamp formats and merge the electricity and weather data.\n",
    "    \"\"\"\n",
    "    console.print(\"[yellow]Standardizing timestamps...[/yellow]\")\n",
    "    if 'timestamp' in electricity_df.columns:\n",
    "        electricity_df['timestamp'] = electricity_df['timestamp'].dt.tz_localize(None)\n",
    "    if 'timestamp' in weather_df.columns:\n",
    "        weather_df['timestamp'] = weather_df['timestamp'].dt.tz_localize(None)\n",
    "    merged = pd.merge(electricity_df, weather_df, on=\"timestamp\", how=\"inner\")\n",
    "    console.print(f\"[cyan]✅ Data Merged Successfully: {merged.shape[0]} records, {merged.shape[1]} features.[/cyan]\")\n",
    "    return merged\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the merged data: impute missing values, remove duplicates,\n",
    "    and add time-based features.\n",
    "    \"\"\"\n",
    "    console.rule(\"[bold blue]Step 2: Data Preprocessing[/bold blue]\")\n",
    "    console.print(\"[yellow]Analyzing missing data...[/yellow]\")\n",
    "    missing = df.isnull().sum() / len(df) * 100\n",
    "    console.print(\"Missing Values (% per column):\")\n",
    "    console.print(missing)\n",
    "    df.ffill(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    console.print(\"[green]✅ Missing values handled and duplicates removed![/green]\")\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    \n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "    \n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    console.print(\"[green]✅ Data Preprocessed Successfully![/green]\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis and generate aesthetically enhanced plots.\n",
    "    \"\"\"\n",
    "    console.rule(\"[bold blue]Step 3: Exploratory Data Analysis (EDA)[/bold blue]\")\n",
    "    \n",
    "    # Statistical Summary\n",
    "    console.print(\"[yellow]Statistical Summary:[/yellow]\")\n",
    "    stats = df.describe().T\n",
    "    stats['skewness'] = df.select_dtypes(include=[np.number]).apply(skew)\n",
    "    stats['kurtosis'] = df.select_dtypes(include=[np.number]).apply(kurtosis)\n",
    "    console.print(stats)\n",
    "    \n",
    "    # Time Series Plot\n",
    "    plt.figure()\n",
    "    plt.plot(df['timestamp'], df['electricity_demand'], color=\"mediumblue\", linewidth=2, label=\"Electricity Demand\")\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Electricity Demand')\n",
    "    plt.title('Electricity Demand Over Time')\n",
    "    plt.xticks(rotation=45)\n",
    "    if not df.empty:\n",
    "        peak = df['electricity_demand'].idxmax()\n",
    "        plt.annotate('Peak Demand',\n",
    "                     xy=(df.loc[peak, 'timestamp'], df.loc[peak, 'electricity_demand']),\n",
    "                     xytext=(df.loc[peak, 'timestamp'], df.loc[peak, 'electricity_demand'] * 1.05),\n",
    "                     arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Univariate Plots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 6))\n",
    "    sns.histplot(df['electricity_demand'], kde=True, color=\"slateblue\", edgecolor=\"black\", ax=axs[0])\n",
    "    axs[0].set_title(\"Histogram & Density\")\n",
    "    sns.boxplot(y=df['electricity_demand'], color=\"lightseagreen\", ax=axs[1])\n",
    "    axs[1].set_title(\"Boxplot\")\n",
    "    sns.kdeplot(df['electricity_demand'], fill=True, color=\"crimson\", ax=axs[2])\n",
    "    axs[2].set_title(\"KDE Density Plot\")\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"Electricity Demand\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation Heatmap\n",
    "    plt.figure()\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    sns.heatmap(numeric_df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Advanced Time Series Analysis: Seasonal Decomposition\n",
    "    try:\n",
    "        # Resample to daily frequency and fill missing values\n",
    "        ts = df.set_index('timestamp')['electricity_demand'].resample('D').mean().ffill()\n",
    "        decomposition = seasonal_decompose(ts, model='additive', period=7)\n",
    "        fig = decomposition.plot()\n",
    "        fig.set_size_inches(14, 10)\n",
    "        plt.suptitle(\"Seasonal Decomposition of Electricity Demand\", fontsize=18)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]❌ Seasonal Decomposition failed: {e}[/red]\")\n",
    "    \n",
    "    # Augmented Dickey-Fuller Test\n",
    "    try:\n",
    "        adf_result = adfuller(ts)\n",
    "        console.print(\"[yellow]Augmented Dickey-Fuller Test Results:[/yellow]\")\n",
    "        console.print(f\"ADF Statistic: {adf_result[0]:.4f}\")\n",
    "        console.print(f\"p-value: {adf_result[1]:.4f}\")\n",
    "        if adf_result[1] < 0.05:\n",
    "            console.print(\"[green]The time series is likely stationary.[/green]\")\n",
    "        else:\n",
    "            console.print(\"[red]The time series is likely non-stationary.[/red]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]❌ ADF Test failed: {e}[/red]\")\n",
    "    \n",
    "    console.print(\"[green]✅ EDA Completed Successfully![/green]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_handle_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect outliers using IQR and Z-score methods and return a cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    console.rule(\"[bold blue]Step 4: Outlier Detection and Handling[/bold blue]\")\n",
    "    \n",
    "    # Plot before outlier removal\n",
    "    plt.figure()\n",
    "    sns.histplot(df['electricity_demand'], kde=True, color=\"darkorange\", edgecolor=\"black\")\n",
    "    plt.title(\"Electricity Demand Distribution (Before Outlier Removal)\")\n",
    "    plt.xlabel(\"Electricity Demand\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # IQR-based filtering\n",
    "    Q1 = df['electricity_demand'].quantile(0.25)\n",
    "    Q3 = df['electricity_demand'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_iqr = df[(df['electricity_demand'] >= Q1 - 1.5 * IQR) &\n",
    "                (df['electricity_demand'] <= Q3 + 1.5 * IQR)]\n",
    "    \n",
    "    # Z-score filtering on numeric columns\n",
    "    numeric_df = df_iqr.select_dtypes(include=[np.number])\n",
    "    z_scores = np.abs(zscore(numeric_df))\n",
    "    df_clean = df_iqr[(z_scores < 3).all(axis=1)]\n",
    "    \n",
    "    # Plot after outlier removal\n",
    "    plt.figure()\n",
    "    sns.histplot(df_clean['electricity_demand'], kde=True, color=\"mediumpurple\", edgecolor=\"black\")\n",
    "    plt.title(\"Electricity Demand Distribution (After Outlier Removal)\")\n",
    "    plt.xlabel(\"Electricity Demand\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    console.print(\"[green]✅ Outliers detected and removed successfully![/green]\")\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_modeling(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform regression analysis on the cleaned dataset and return predictions.\n",
    "    \"\"\"\n",
    "    console.rule(\"[bold blue]Step 5: Regression Modeling[/bold blue]\")\n",
    "    \n",
    "    if 'temperature_2m' not in df.columns:\n",
    "        console.print(\"[red]❌ ERROR: 'temperature_2m' column is missing from weather data![/red]\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    X = df[['hour', 'day', 'month', 'temperature_2m']]\n",
    "    y = df['electricity_demand']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    console.print(f\"✅ Model Trained! MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    # Plot Actual vs Predicted\n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, y_pred, color='mediumblue', alpha=0.6, edgecolor=\"black\")\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel(\"Actual Demand\")\n",
    "    plt.ylabel(\"Predicted Demand\")\n",
    "    plt.title(\"Actual vs. Predicted Electricity Demand\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Residual analysis\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure()\n",
    "    sns.histplot(residuals, kde=True, color=\"darkslategray\", edgecolor=\"black\")\n",
    "    plt.title(\"Residuals Distribution\")\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(y_pred, residuals, color=\"teal\", alpha=0.6, edgecolor=\"black\")\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel(\"Predicted Demand\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals vs. Predicted Values\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    console.print(\"[green]✅ Regression modeling and residual analysis completed successfully![/green]\")\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"Actual\": y_test,\n",
    "        \"Predicted\": y_pred,\n",
    "        \"Residual\": residuals\n",
    "    })\n",
    "    return predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis():\n",
    "    \"\"\"\n",
    "    Main function to run the complete analysis pipeline.\n",
    "    \"\"\"\n",
    "    console.rule(\"[bold blue]Step 1: Data Loading & Integration[/bold blue]\")\n",
    "    \n",
    "    # Define paths (update the paths as necessary for your environment)\n",
    "    base_path = r\"/Users/muhammadsarim/Desktop/22F-3688_BSE-6B_AssNO.2\"\n",
    "    elec_folder = os.path.join(base_path, \"electricity_raw_data\")\n",
    "    weather_folder = os.path.join(base_path, \"weather_raw_data\")\n",
    "    \n",
    "    # Load datasets\n",
    "    electricity_df = load_electricity_data(elec_folder)\n",
    "    weather_df = load_weather_data(weather_folder)\n",
    "    \n",
    "    # Merge datasets\n",
    "    merged_df = merge_datasets(electricity_df, weather_df)\n",
    "    console.print(f\"[blue]Initial merged data: {merged_df.shape[0]} records, {merged_df.shape[1]} features.[/blue]\")\n",
    "    \n",
    "    # Preprocess data and add features\n",
    "    processed_df = preprocess_data(merged_df)\n",
    "    \n",
    "    # Exploratory Data Analysis\n",
    "    perform_eda(processed_df)\n",
    "    \n",
    "    # Outlier detection and cleaning\n",
    "    clean_df = detect_and_handle_outliers(processed_df)\n",
    "    \n",
    "    # Remove the 'season' column before generating the final CSV\n",
    "    if 'season' in clean_df.columns:\n",
    "        clean_df = clean_df.drop(columns=['season'])\n",
    "    \n",
    "    # Generate final cleaned and processed CSV\n",
    "    final_csv_path = os.path.join(base_path, \"final_cleaned_processed_data.csv\")\n",
    "    clean_df.to_csv(final_csv_path, index=False)\n",
    "    console.print(f\"[green]Final cleaned and processed data saved at: {final_csv_path}[/green]\")\n",
    "    \n",
    "    # Regression modeling\n",
    "    predictions_df = regression_modeling(clean_df)\n",
    "    if not predictions_df.empty:\n",
    "        console.print(\"[green]Regression modeling completed and predictions obtained.[/green]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_analysis()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
